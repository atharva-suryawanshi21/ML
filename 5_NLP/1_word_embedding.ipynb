{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Word embedding is a core concept in Natural Language Processing (NLP) where words are represented as numerical vectors.\n",
    "2. This technique is crucial for NLP tasks, enabling machines to understand word meanings and relationships.\n",
    "Significance of Word Embedding:\n",
    "\n",
    "3. Word embedding captures semantic relationships, making it a key component in NLP applications like sentiment analysis and machine translation.\n",
    "4. It reduces dimensionality, improving model performance and facilitating the processing of large text corpora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = {\n",
    "    'very nice food',\n",
    "    'amazing restaurant',\n",
    "    'very bad',\n",
    "    'too good',\n",
    "    'just loved it',\n",
    "    'will go again',\n",
    "    'horrible food',\n",
    "    'never go there',\n",
    "    'poor service',\n",
    "    'poor quality',\n",
    "    'very good',\n",
    "    'needs improvement'\n",
    "}\n",
    "sentiments = np.array([1,1,0,1,1,1,0,0,0,0,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert into one hot vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 'encoded_review' will contain lists of integers, where each integer corresponds to a word in the input text. \n",
    "2. The vocabulary size is set to 30, and the function assigns unique integers to the words in the input text within that vocabulary size constraint. \n",
    "3. The specific integer assigned to each word is determined by the hashing function used by one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 9, 27],\n",
       " [15, 5],\n",
       " [14, 19, 28],\n",
       " [14, 16],\n",
       " [24, 15],\n",
       " [8, 20, 24],\n",
       " [1, 24],\n",
       " [17, 19, 26],\n",
       " [8, 7],\n",
       " [12, 14],\n",
       " [12, 29],\n",
       " [8, 16]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\n",
    "vocabulary_size = 30\n",
    "encoded_review = [one_hot(sentence, vocabulary_size) for sentence in reviews]\n",
    "encoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding\n",
    "1. Some sentences are 3 word long and some ar 4.\n",
    "2. So we need padding to have uniform size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  9, 27],\n",
       "       [15,  5,  0],\n",
       "       [14, 19, 28],\n",
       "       [14, 16,  0],\n",
       "       [24, 15,  0],\n",
       "       [ 8, 20, 24],\n",
       "       [ 1, 24,  0],\n",
       "       [17, 19, 26],\n",
       "       [ 8,  7,  0],\n",
       "       [12, 14,  0],\n",
       "       [12, 29,  0],\n",
       "       [ 8, 16,  0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 3\n",
    "padded_reviews = pad_sequences(encoded_review, maxlen = max_length, padding = 'post')\n",
    "padded_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 4)              120       \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 12)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedded_vector_size = 4\n",
    "train = padded_reviews\n",
    "targets = sentiments\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Embedding(vocabulary_size, embedded_vector_size, input_length = max_length, name = 'embedding'),\n",
    "    Flatten(),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile('adam', loss = 'binary_crossentropy', metrics =['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 579ms/step - loss: 0.6919 - accuracy: 0.5833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6918697357177734, 0.5833333134651184]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train,targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
