{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "1. Introduction to Transfer Learning:\n",
    "\n",
    "- Transfer learning is a machine learning technique where a pre-trained model developed for one task is reused as the starting point for a model on a second task.\n",
    "- It leverages the knowledge gained while solving one problem and applies it to a different but related problem.\n",
    "2. Why Transfer Learning?:\n",
    "\n",
    "- Transfer learning saves time and computational resources since you start with a model that has already learned useful features from a large dataset.\n",
    "- It often leads to better performance, especially when you have limited data for the specific task you want to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will have deeper understanding of transfer learning at the end of this notebook. So for now, we follow below steps:\n",
    "1. Take pretrained model:- mobilenet v2, this model classifies 1000 classes(doesn't include any flower classification).\n",
    "- The pretained model perfors terrible on the flower dataset(tf_flowers) as it was not trained for it's classification.\n",
    "2. Freeze all the layers except the last one.\n",
    "3. Train the last year for our flowers dataset - tf_flowers, (roses,tulips,sunflower,etc).\n",
    "4. Get result.\n",
    "5. Explaination of all the working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Relevant Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the flowers dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin = dataset_url, cache_dir = '\"C:/Users/satha/Downloads/datasets\"', untar = True)\n",
    "\n",
    "# Explaination done in tf_flowers project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('/tmp/.keras/datasets/flower_photos')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "data_dir\n",
    "\n",
    "# Explaination done in tf_flowers project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we create a dictionary for all the flower image paths and corresponding labels\n",
    "\n",
    "flower_image_dic = {\n",
    "                        \"roses\" : list(data_dir.glob('roses/*')),\n",
    "                        \"daisy\" : list(data_dir.glob('daisy/*')),\n",
    "                        \"dandelion\" : list(data_dir.glob('dandelion/*')),\n",
    "                        \"sunflowers\" : list(data_dir.glob('sunflowers/*')),\n",
    "                        \"tulips\" : list(data_dir.glob('tulips/*'))\n",
    "                    }\n",
    "\n",
    "flower_labels_dic = {\n",
    "                        'roses' : 0,\n",
    "                        'daisy' : 1,\n",
    "                        'dandelion': 2,\n",
    "                        'sunflowers': 3,\n",
    "                        'tulips' : 4\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we do the following:\n",
    "1. read each file into numpy array via path by using: \n",
    "-  cv2.imread( str( file_path [index] ))\n",
    "2. Resize all the image shapes into one value\n",
    "3. store resized image array into a list\n",
    "4. store corresponding label into another list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x , y =[], []\n",
    "image_size = (224,224)\n",
    "for flower_name, images in flower_image_dic.items():\n",
    "    for image in images:\n",
    "        img = cv2.imread(str(image))\n",
    "        resized_img = cv2.resize(img, image_size)\n",
    "        x.append(resized_img)\n",
    "        y.append(flower_labels_dic[flower_name])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we do the following:\n",
    "1. convert x and y to numpy arrays\n",
    "2. scale the data\n",
    "3. split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_inputs, test_inputs,train_targets, test_targets = train_test_split(x,y,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage if we feed this data into mobilenet v2 pretrained model, the model that has been trained on more than 1 million inputs , we will fail to classify these flowers(as it was not trained to classify into these flowers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretrained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "pretrained_model_without_last_layer = hub.KerasLayer(\n",
    "    feature_extractor_model, \n",
    "    input_shape=(224,224,3), \n",
    "    trainable = False   # freeze layers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1st line gives the pretrained model without the last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we create our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 6405      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,264,389\n",
      "Trainable params: 6,405\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "no_of_flowers = 5\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                                pretrained_model_without_last_layer,\n",
    "\n",
    "                                tf.keras.layers.Dense(no_of_flowers)\n",
    "                            ])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: \n",
    "1. We used loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True) instead of loss = 'sparse_categorical_crossentropy'\n",
    "2. In our model we did not add any layer for softmax function, the above loss ensures it's been used externally.\n",
    "3. This argument indicates that the model's output is provided in the form of logits. Logits are the raw, unnormalized scores produced by the model before converting them into probabilities using a softmax activation function. In other words, the model's output is assumed to be the pre-softmax values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "86/86 [==============================] - 54s 545ms/step - loss: 0.8319 - accuracy: 0.6879\n",
      "Epoch 2/5\n",
      "86/86 [==============================] - 42s 485ms/step - loss: 0.4292 - accuracy: 0.8514\n",
      "Epoch 3/5\n",
      "86/86 [==============================] - 33s 387ms/step - loss: 0.3387 - accuracy: 0.8859\n",
      "Epoch 4/5\n",
      "86/86 [==============================] - 30s 347ms/step - loss: 0.2830 - accuracy: 0.9135\n",
      "Epoch 5/5\n",
      "86/86 [==============================] - 32s 377ms/step - loss: 0.2426 - accuracy: 0.9281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18261995fc0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_inputs,train_targets, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test it on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 11s 357ms/step - loss: 0.3441 - accuracy: 0.8791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34413328766822815, 0.8790849447250366]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got accuracy of 88 percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaination of Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How does changing only the last layer, makes the model learn about classification of flowers, even though it was not pretrained for it to begin with?\n",
    "- The early layers of the model learn general features like edges and textures, which can be applied to various tasks, including flower classification. By adding a new output layer for your specific classes (e.g., roses, tulips), and training only this new layer while keeping the rest fixed, you reuse the valuable features learned by the pre-trained model. The initial layers capture basic features useful for many tasks, including distinguishing between different flowers. Essentially, you're using the model's prior knowledge and fine-tuning it for your unique classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Arent the frezzed layer optimised to predict the 1000 classes meantioned in that pretrained model, then how can it predict flowers?\n",
    "- The frozen layers are designed to extract general image features like edges, shapes, and textures, which are useful but not task-specific. Freezing them preserves their feature-extraction abilities. You're essentially letting the model fine-tune its final classification layer for your specific task while capitalizing on these pre-learned features.\n",
    "- In MobileNetV2, mid-level features represent general visual patterns and textures from its original training, including shapes, textures, and colors relevant to various objects, including flowers. When fine-tuning for flower classification, you leverage the model's image understanding capabilities, even though it wasn't originally for flowers. Success comes from recognizing general visual patterns, textures, and shapes, not specific flower knowledge. So, while not initially designed for flowers, MobileNetV2's mid-level features adapt to recognize flower-related features effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What are the features learned by these freezed layers?\n",
    "- Low-Level Features:\n",
    "\n",
    "   - Edges: The frozen layers capture essential edge information, crucial for distinguishing petal edges and flower boundaries.\n",
    "   - Textures: These layers recognize simple textures found in flower petals, leaves, or backgrounds.\n",
    "   - Colors: The model learns a variety of colors and color combinations, aiding in flower color identification.\n",
    "- Mid-Level Features:\n",
    "\n",
    "   - Geometric Patterns: These layers detect complex patterns, such as petal or leaf arrangements in different flowers.\n",
    "   - Basic Shapes: They identify basic shapes that characterize specific types of flowers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
