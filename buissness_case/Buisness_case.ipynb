{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "983f5b00",
   "metadata": {},
   "source": [
    "# Assembling the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c12809",
   "metadata": {},
   "source": [
    "### Task\n",
    "To create a machine learning algorithm, which is able to predict if a customer will buy again. This classification has two classes, won't buy and will buy, represented by 0 and 1 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125a7a6b",
   "metadata": {},
   "source": [
    "### Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc0fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f89620",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1025aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('Audiobook_train_data.npz')\n",
    "\n",
    "train_inputs = npz['inputs'].astype(float)\n",
    "train_targets = npz['targets'].astype(float)\n",
    "# astype() creates a copy of the array, cast to a specific type\n",
    "# to ensure our model learns correctly we accept all inputs to be float\n",
    "# even though our targets are 0 and 1, we are not completely certain that they will extracted as integers, floats or booleans, so we cast targets too\n",
    "\n",
    "npz = np.load('Audiobook_validation_data.npz')\n",
    "\n",
    "validation_inputs = npz['inputs'].astype(float)\n",
    "validation_targets = npz['targets'].astype(float)\n",
    "\n",
    "npz = np.load('Audiobook_test_data.npz')\n",
    "\n",
    "test_inputs , test_targets = npz['inputs'].astype(float) , npz['targets'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba4f86",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f6c603",
   "metadata": {},
   "source": [
    "Outline, Optimizers, Loss, Early Stopping and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d969694c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 1s - loss: 0.6377 - accuracy: 0.6354 - val_loss: 0.5329 - val_accuracy: 0.7472 - 890ms/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "36/36 - 0s - loss: 0.5215 - accuracy: 0.7455 - val_loss: 0.4629 - val_accuracy: 0.7673 - 123ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "36/36 - 0s - loss: 0.4753 - accuracy: 0.7522 - val_loss: 0.4313 - val_accuracy: 0.7651 - 118ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "36/36 - 0s - loss: 0.4488 - accuracy: 0.7678 - val_loss: 0.4127 - val_accuracy: 0.7740 - 111ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "36/36 - 0s - loss: 0.4347 - accuracy: 0.7804 - val_loss: 0.4044 - val_accuracy: 0.7718 - 110ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "36/36 - 0s - loss: 0.4194 - accuracy: 0.7832 - val_loss: 0.3964 - val_accuracy: 0.7785 - 107ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "36/36 - 0s - loss: 0.4131 - accuracy: 0.7846 - val_loss: 0.3902 - val_accuracy: 0.7830 - 108ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "36/36 - 0s - loss: 0.4065 - accuracy: 0.7885 - val_loss: 0.3820 - val_accuracy: 0.7987 - 95ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "36/36 - 0s - loss: 0.3957 - accuracy: 0.7952 - val_loss: 0.3770 - val_accuracy: 0.7942 - 109ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "36/36 - 0s - loss: 0.3974 - accuracy: 0.7902 - val_loss: 0.3749 - val_accuracy: 0.7964 - 114ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "36/36 - 0s - loss: 0.3928 - accuracy: 0.7910 - val_loss: 0.3735 - val_accuracy: 0.7919 - 94ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "36/36 - 0s - loss: 0.3919 - accuracy: 0.7910 - val_loss: 0.3742 - val_accuracy: 0.7919 - 101ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b6cc139ba0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 10\n",
    "hidden_layer_size = 50\n",
    "output_size = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                                tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "                                tf.keras.layers.Dropout(0.2),\n",
    "                                tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "                                tf.keras.layers.Dropout(0.2),\n",
    "                                tf.keras.layers.Dense(output_size, activation = 'softmax')\n",
    "                            ])\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "max_epochs = 100\n",
    "\n",
    "# we can feed  2 tuple object or two simple seperated  arrays when feeding training data\n",
    "# when dealing with arrays, indicating batch size will automatically batch the data during the training process\n",
    "'''\n",
    "# case 1: no early stopping\n",
    "model.fit(train_inputs, \n",
    "          train_targets,\n",
    "          batch_size= batch_size,\n",
    "          epochs = max_epochs,\n",
    "          validation_data = (validation_inputs, validation_targets),\n",
    "          verbose = 2,\n",
    "         )\n",
    "'''\n",
    "# case 2: with early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=1)\n",
    "# by defualt it stops the first time the validation loss starts increasing.\n",
    "model.fit(train_inputs, \n",
    "          train_targets,\n",
    "          batch_size= batch_size,\n",
    "          epochs = max_epochs,\n",
    "          callbacks = [early_stopping],  # list of callbacks []\n",
    "          validation_data = (validation_inputs, validation_targets),\n",
    "          verbose = 2,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a9a77",
   "metadata": {},
   "source": [
    "1. In case no early stopping : When we train our model for so long, there is a chance that we are overfitting the model. As the loss was decreasing consistently, our validation loss was sometimes increasing and sometimes decreasing -> we have over fitted our model\n",
    "2. In case of early stopping: fit() contains an argument called callbacks. These are functions called at certain steps during model training. We will focus on EarlyStopping. Here each time the validation loss is calculated, it is compared to the validation loss one epoch ago, if it starts increasing , our model is overfitting.\n",
    "3. When the validation loss increase is significantly low, we may slide 1 or 2 validation increases. Hence we adjust EarlyStopping for this Tolerance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e70c7f",
   "metadata": {},
   "source": [
    "### Test the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "819a5f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3501260578632355, 0.8035714030265808]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_inputs,test_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
